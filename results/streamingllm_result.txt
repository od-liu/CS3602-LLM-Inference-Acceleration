HF_HUB_OFFLINE=1 python scripts/benchmark.py --method streaming_llm --max_tokens 2024 --num_samples 10
======================================================================
KV Cache Compression Benchmark
======================================================================

Configuration:
  Model: EleutherAI/pythia-70m-deduped
  Method: streaming_llm
  Skip layers: [0, 1]
  Number of samples: 10
  Max eval tokens: 2024
  Max new tokens: 500
Loading model: EleutherAI/pythia-70m-deduped
Using device: mps

Loading PG-19 dataset...
  Found local file: /Users/od/Desktop/NLP/CS3602-LLM-Inference-Acceleration/data/pg19.parquet
  Loaded 100 samples from local file
  Sample 1: 249431 characters
  Sample 2: 318194 characters
  Sample 3: 309465 characters
  Sample 4: 343094 characters
  Sample 5: 23870 characters
  Sample 6: 216914 characters
  Sample 7: 432117 characters
  Sample 8: 128528 characters
  Sample 9: 345713 characters
  Sample 10: 100250 characters
  Total: 10 samples loaded

Methods to test:
  - baseline: {}
  - streaming_256: {'start_size': 4, 'recent_size': 252}
  - streaming_512: {'start_size': 4, 'recent_size': 508}
  - streaming_1024: {'start_size': 4, 'recent_size': 1020}

================================================================================
AGGREGATED RESULTS (averaged across samples)
================================================================================

Method                       TTFT(s)    TPOT(s)    Thruput        PPL        Acc    Cache
------------------------------------------------------------------------------------------
baseline                      0.0090     0.0059     168.71      39.99     35.49%     2023
streaming_256                 0.0065     0.0074     135.37      43.06     34.49%     2023
streaming_512                 0.0074     0.0071     140.05      41.45     35.04%     2023
streaming_1024                0.0076     0.0074     136.03      40.78     35.31%     2023
==========================================================================================

Comparison with baseline:
  streaming_256: TTFT +27.5%, PPL +7.7%, Acc -2.8%
  streaming_512: TTFT +17.5%, PPL +3.7%, Acc -1.3%
  streaming_1024: TTFT +16.1%, PPL +2.0%, Acc -0.5%

====================================================
运行命令行：
python scripts/benchmark.py --method streaming_llm \
--max_tokens 5000 \
--recent_sizes 252,508,1020 \
--num_samples 5

================================================================================
AGGREGATED RESULTS (averaged across samples)
================================================================================

Method                       TTFT(s)    TPOT(s)    Thruput        PPL        Acc    Cache
------------------------------------------------------------------------------------------
baseline                      0.0163     0.0083     123.30     124.28     26.19%     4999
streaming_256                 0.0131     0.0115      90.36     168.93     25.10%     4999
streaming_512                 0.0138     0.0106      94.40     164.10     25.46%     4999
streaming_1024                0.0140     0.0110      90.58     161.96     25.66%     4999
==========================================================================================

Comparison with baseline:
  streaming_256: TTFT +19.8%, PPL +35.9%, Acc -4.2%
  streaming_512: TTFT +15.3%, PPL +32.0%, Acc -2.8%
  streaming_1024: TTFT +14.2%, PPL +30.3%, Acc -2.0%

==================================================================
运行命令行：
python scripts/benchmark.py --method streaming_llm \
    --max_tokens 50000 \
    --recent_sizes 252,508,1020 \
    --num_samples 3


Testing: baseline
============================================================
PPL: 638.30, Acc: 17.53%: 100%|███████████████████████████████████████████████████████████████████████| 9999/9999 [03:07<00:00, 53.20it/s]

Generation Metrics:
  TTFT:       0.0238 seconds
  TPOT:       0.0053 seconds
  Throughput: 186.87 tokens/sec

Quality Metrics:
  PPL:        638.30
  Accuracy:   17.53%
  Cache size: 9999 tokens

============================================================
Testing: streaming_256
============================================================
PPL: 604.37, Acc: 17.40%: 100%|██████████████████████████████████████████████████████████████████████| 9999/9999 [01:29<00:00, 111.84it/s]

Generation Metrics:
  TTFT:       0.1820 seconds
  TPOT:       0.0089 seconds
  Throughput: 107.64 tokens/sec
python scripts/benchmark.py --method streaming_llm \
    --max_tokens 30000 \
    --recent_sizes 252,508,1020 \
    --num_samples 10 --num_warmup 20
======================================================================
KV Cache Compression Benchmark
======================================================================

Configuration:
  Model: EleutherAI/pythia-70m-deduped
  Method: streaming_llm
  Skip layers: [0, 1]
  Number of samples: 10
  Max eval tokens: 30000
  Max new tokens: 500
  Warmup iterations: 20
Loading model: EleutherAI/pythia-70m-deduped
Using device: mps

Performing 20 warmup iterations...
  Warmup 1/20 completed
  Warmup 2/20 completed
  Warmup 3/20 completed
  Warmup 4/20 completed
  Warmup 5/20 completed
  Warmup 6/20 completed
  Warmup 7/20 completed
  Warmup 8/20 completed
  Warmup 9/20 completed
  Warmup 10/20 completed
  Warmup 11/20 completed
  Warmup 12/20 completed
  Warmup 13/20 completed
  Warmup 14/20 completed
  Warmup 15/20 completed
  Warmup 16/20 completed
  Warmup 17/20 completed
  Warmup 18/20 completed
  Warmup 19/20 completed
  Warmup 20/20 completed
  ================================================================================
AGGREGATED RESULTS (averaged across samples)
================================================================================

Method                       TTFT(s)    TPOT(s)    Thruput        PPL        Acc    Cache
------------------------------------------------------------------------------------------
baseline                      0.0074     0.0100      96.25    1646.10     10.97%    27313
streaming_256                 0.0075     0.0086     104.19    2906.07     10.30%    27313
streaming_512                 0.0066     0.0085     105.72    2865.64     10.43%    27313
streaming_1024                0.0066     0.0085     106.10    2845.13     10.49%    27313
==========================================================================================