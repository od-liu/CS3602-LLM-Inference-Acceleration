# CS3602 LLM Inference Acceleration

CS3602å¤§ä½œä¸šï¼šé’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„KV Cacheä¼˜åŒ–ä¸æ¨ç†åŠ é€Ÿã€‚

æœ¬é¡¹ç›®å®ç°äº†å¤šç§ KV Cache å‹ç¼©æ–¹æ³•ï¼Œç»Ÿä¸€åœ¨ `kvcompress` åº“ä¸­ç®¡ç†ï¼š

1. **L2 Compress (KnormPress)** - åŸºäº L2 èŒƒæ•°çš„æ¯”ä¾‹å‹ç¼©
2. **Fix-Size L2** - å›ºå®šå¤§å° KV Cache å‹ç¼©
3. **StreamingLLM** - åŸºäº Attention Sink çš„æµå¼å‹ç¼©

## é¡¹ç›®æ¦‚è¿°

KVCompress æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ KV Cache å‹ç¼©åº“ï¼Œæ”¯æŒå¤šç§å‹ç¼©ç­–ç•¥ï¼š

| æ–¹æ³• | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| `l2_compress` | æŒ‰ `keep_ratio` æ¯”ä¾‹å‹ç¼©ï¼Œä¿ç•™ä½ L2 èŒƒæ•° token | é€šç”¨å‹ç¼© |
| `fix_size_l2_compress` | ç»´æŒå›ºå®š KV Cache å¤§å°ï¼Œæ”¯æŒå¤šç§é©±é€ç­–ç•¥ | å†…å­˜å—é™åœºæ™¯ |
| `streaming_llm_compress` | ä¿ç•™ attention sinks + æœ€è¿‘ tokens | æ— é™é•¿åº¦æµå¼è¾“å…¥ |

### StreamingLLM æ–¹æ³•

StreamingLLM æ˜¯æ¥è‡ª MIT Han Lab çš„æ–¹æ³•ï¼ˆICLR 2024ï¼‰ï¼Œæ ¸å¿ƒå‘ç°æ˜¯ï¼š

- LLM ä¼šå°†å¤§é‡ attention åˆ†é…ç»™åˆå§‹ tokensï¼ˆ"attention sinks"ï¼‰ï¼Œå³ä½¿å®ƒä»¬è¯­ä¹‰ä¸Šä¸é‡è¦
- é€šè¿‡ä¿ç•™è¿™äº› attention sinks + æ»‘åŠ¨çª—å£çš„æœ€è¿‘ tokensï¼Œå¯ä»¥å¤„ç†æ— é™é•¿åº¦çš„è¾“å…¥

```
Cache ç»“æ„: [initial tokens (0:start_size)] + [recent tokens (seq_len-recent_size:seq_len)]
é»˜è®¤é…ç½®: 4 initial tokens + 508 recent tokens = 512 total
```

## é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ LICENSE                      # è®¸å¯è¯
â”œâ”€â”€ results.txt                  # å®éªŒç»“æœæ—¥å¿—
â”‚
â”œâ”€â”€ docs/                        # ğŸ“š æ–‡æ¡£
â”‚   â”œâ”€â”€ lab-instruction.md       # ä½œä¸šè¦æ±‚
â”‚   â”œâ”€â”€ KnormPress.pdf           # KnormPress è®ºæ–‡
â”‚   â””â”€â”€ L2_COMPRESS_ANALYSIS.md  # å‹ç¼©æ•ˆæœåˆ†æ
â”‚
â”œâ”€â”€ data/                        # ğŸ“Š æ•°æ®é›†
â”‚   â””â”€â”€ pg19.parquet             # PG-19 é•¿æ–‡æœ¬æ•°æ®é›†
â”‚
â”œâ”€â”€ kvcompress/                  # ğŸ§  æ ¸å¿ƒå‹ç¼©åº“ â­
â”‚   â”œâ”€â”€ __init__.py              # ç»Ÿä¸€å¯¼å‡º
â”‚   â”œâ”€â”€ methods/                 # å‹ç¼©æ–¹æ³•
â”‚   â”‚   â”œâ”€â”€ __init__.py          # æ–¹æ³•æ³¨å†Œè¡¨
â”‚   â”‚   â”œâ”€â”€ base.py              # åŸºç±»å’Œæ¥å£
â”‚   â”‚   â”œâ”€â”€ l2_compress.py       # KnormPress L2 å‹ç¼©
â”‚   â”‚   â”œâ”€â”€ fix_size_l2.py       # å›ºå®šå¤§å° L2 å‹ç¼©
â”‚   â”‚   â””â”€â”€ streaming_llm.py     # StreamingLLM æ–¹æ³• â­
â”‚   â”œâ”€â”€ evaluate.py              # ç»Ÿä¸€è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ benchmark.py             # ç»Ÿä¸€åŸºå‡†æµ‹è¯•æ¨¡å—
â”‚   â””â”€â”€ utils.py                 # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ scripts/                     # ğŸ› ï¸ å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ benchmark.py             # ç»Ÿä¸€åŸºå‡†æµ‹è¯•å…¥å£ â­
â”‚   â””â”€â”€ plot_compression_results.py  # å¯è§†åŒ–ç»˜å›¾
â”‚
â”œâ”€â”€ baseline_test.py             # åŸºçº¿æ€§èƒ½æµ‹è¯•
â”‚
â””â”€â”€ results/                     # ğŸ“ˆ ç»“æœå›¾è¡¨
    â”œâ”€â”€ strategy_comparison.png      # ç­–ç•¥å¯¹æ¯”å›¾
    â”œâ”€â”€ keep_ratio_analysis.png      # Keep Ratio åˆ†æå›¾
    â”œâ”€â”€ ppl_accuracy_tradeoff.png    # PPL-Accuracy æƒè¡¡å›¾
    â”œâ”€â”€ improvement_summary.png      # æ”¹è¿›æ€»ç»“å›¾
    â””â”€â”€ compression_comparison.png   # å‹ç¼©æ•ˆæœå¯¹æ¯”å›¾
```

## ç¯å¢ƒé…ç½®

### ä¾èµ–å®‰è£…

```bash
# åˆ›å»ºå¹¶æ¿€æ´» conda ç¯å¢ƒ
conda create -n nlp python=3.11
conda activate nlp

# å®‰è£…ä¾èµ–
pip install torch transformers datasets numpy tqdm
```

### æ¨¡å‹å’Œæ•°æ®é›†

- **æ¨¡å‹**: `EleutherAI/pythia-2.8b`
- **æ•°æ®é›†**: `PG-19` (é•¿æ–‡æœ¬), `wikitext-2-raw-v1` (çŸ­æ–‡æœ¬)

## ä½¿ç”¨æ–¹æ³•

### 1. ç»Ÿä¸€åŸºå‡†æµ‹è¯•ï¼ˆæ¨èï¼‰

```bash
# æµ‹è¯• L2 å‹ç¼©ï¼ˆKnormPressï¼‰
python scripts/benchmark.py --method l2_compress --keep_ratios 1.0,0.8,0.5

# æµ‹è¯•å›ºå®šå¤§å° L2 å‹ç¼©
python scripts/benchmark.py --method fix_size_l2 --fix_kv_sizes 256,512 --strategies keep_low

# æµ‹è¯• StreamingLLM
python scripts/benchmark.py --method streaming_llm --start_size 4 --recent_sizes 252,508,1020

# å¯¹æ¯”æ‰€æœ‰æ–¹æ³•
python scripts/benchmark.py --compare_all
```

### 2. åœ¨ä»£ç ä¸­ä½¿ç”¨

```python
from kvcompress import (
    l2_compress, 
    fix_size_l2_compress, 
    streaming_llm_compress,
    evaluate_with_compression
)

# æ–¹æ³•1: L2 æ¯”ä¾‹å‹ç¼© (KnormPress)
compressed_kv = l2_compress(
    past_key_values,
    keep_ratio=0.8,      # ä¿ç•™ 80%
    prune_after=1000,    # è¶…è¿‡ 1000 token æ‰å‹ç¼©
    skip_layers=[0, 1]   # è·³è¿‡å‰ä¸¤å±‚
)

# æ–¹æ³•2: å›ºå®šå¤§å°å‹ç¼©
compressed_kv = fix_size_l2_compress(
    past_key_values,
    fix_kv_size=512,       # æœ€å¤šä¿ç•™ 512 token
    keep_ratio=0.2,        # æœ€è¿‘ 20% ä¸é©±é€
    strategy="keep_low",   # ä¿ç•™ä½èŒƒæ•° token
    skip_layers=[0, 1]
)

# æ–¹æ³•3: StreamingLLM
compressed_kv = streaming_llm_compress(
    past_key_values,
    start_size=4,          # ä¿ç•™ 4 ä¸ª attention sink tokens
    recent_size=508,       # ä¿ç•™æœ€è¿‘ 508 ä¸ª tokens
)

# ä½¿ç”¨ç»Ÿä¸€è¯„ä¼°æ¥å£
results = evaluate_with_compression(
    model, tokenizer, text,
    compress_fn=streaming_llm_compress,
    compress_kwargs={"start_size": 4, "recent_size": 508}
)
print(f"PPL: {results['perplexity']:.2f}, Acc: {results['accuracy']:.2%}")
```

### 3. ä½¿ç”¨æ–¹æ³•æ³¨å†Œè¡¨

```python
from kvcompress import get_compress_fn, list_methods

# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ–¹æ³•
print(list_methods())  # ['l2_compress', 'fix_size_l2', 'streaming_llm']

# é€šè¿‡åç§°è·å–å‹ç¼©å‡½æ•°
compress_fn = get_compress_fn("streaming_llm")
compressed = compress_fn(past_key_values, start_size=4, recent_size=508)
```

## æ ¸å¿ƒç®—æ³•

### l2_compress (æ¯”ä¾‹å‹ç¼©)

```
è¾“å…¥: KV Cache (seq_len tokens), keep_ratio
è¾“å‡º: å‹ç¼©åçš„ KV Cache (seq_len * keep_ratio tokens)

1. è®¡ç®—æ¯ä¸ª token çš„ L2 èŒƒæ•°
2. æŒ‰èŒƒæ•°å‡åºæ’åº
3. ä¿ç•™å‰ keep_ratio æ¯”ä¾‹çš„ä½èŒƒæ•° token
4. æ¢å¤æ—¶é—´é¡ºåº
```

### fix_size_l2_compress (å›ºå®šå¤§å°)

```
è¾“å…¥: KV Cache, fix_kv_size, keep_ratio
è¾“å‡º: æœ€å¤š fix_kv_size tokens çš„ KV Cache

1. å¦‚æœ seq_len <= fix_kv_sizeï¼Œä¸å‹ç¼©
2. è®¡ç®—ä¿æŠ¤åŒºå¤§å°: protected = fix_kv_size * keep_ratio
3. é©±é€åŒº = å‰ (seq_len - protected) ä¸ª token
4. ä»é©±é€åŒºé€‰æ‹© (fix_kv_size - protected) ä¸ª token ä¿ç•™
5. åˆå¹¶: ä¿ç•™çš„é©±é€åŒº token + ä¿æŠ¤åŒº token
```

### streaming_llm_compress (StreamingLLM)

```
è¾“å…¥: KV Cache, start_size, recent_size
è¾“å‡º: æœ€å¤š (start_size + recent_size) tokens çš„ KV Cache

1. å¦‚æœ seq_len <= (start_size + recent_size)ï¼Œä¸å‹ç¼©
2. ä¿ç•™ attention sinks: tokens[0:start_size]
3. ä¿ç•™æœ€è¿‘ tokens: tokens[-recent_size:]
4. æ‹¼æ¥: attention sinks + recent tokens
```

## å®éªŒç»“æœ

### Pythia-2.8B åŸºå‡†æµ‹è¯•ç»“æœ

**æµ‹è¯•é…ç½®**:
- æ¨¡å‹: `EleutherAI/pythia-2.8b`
- æ•°æ®é›†: PG-19 é•¿æ–‡æœ¬
- è¯„ä¼° tokens: 2000
- è®¾å¤‡: CUDA GPU

#### è¯¦ç»†æ€§èƒ½æ•°æ®

| æ–¹æ³• | TTFT(s) | TPOT(s) | ååé‡(tok/s) | PPL | Accuracy | Cache Size |
|------|---------|---------|---------------|-----|----------|------------|
| **Baseline** | 0.0247 | 0.0119 | 82.97 | 15.48 | 47.77% | 1999 |
| L2 (kr=0.8) | 0.0085 | 0.0085 | 114.70 | 57.83 | 30.72% | 99 |
| L2 (kr=0.5) | 0.0084 | 0.0084 | 115.93 | 43.74 | 35.29% | 99 |
| Fix-512 (keep_low) | 0.0083 | 0.0124 | 79.46 | 17.66 | 46.40% | 512 |
| **StreamingLLM-512** | 0.0084 | 0.0106 | 92.97 | 15.92 | 47.57% | 512 |
| **StreamingLLM-1024** | 0.0123 | 0.0117 | 84.26 | 15.52 | 47.72% | 1024 |

#### ä¸ Baseline å¯¹æ¯”

| æ–¹æ³• | ååé‡å˜åŒ– | TPOT æå‡ | PPL å˜åŒ– | Accuracy å˜åŒ– |
|------|-----------|----------|---------|--------------|
| L2 (kr=0.8) | +38.2% | +28.3% | +273.5% âŒ | -35.7% âŒ |
| L2 (kr=0.5) | +39.7% | +29.1% | +182.5% âŒ | -26.1% âŒ |
| Fix-512 (keep_low) | -4.2% | -4.2% | +14.1% | -2.9% |
| **StreamingLLM-512** | **+12.1%** | **+11.2%** | **+2.8%** | **-0.4%** âœ… |
| **StreamingLLM-1024** | +1.6% | +1.8% | **+0.3%** | **-0.1%** âœ… |

### å…³é”®å‘ç°

ğŸ† **æœ€ä½³æ–¹æ³•: StreamingLLM**
- **StreamingLLM-512**: ååé‡æå‡ 12.1%ï¼ŒPPL ä»…å¢åŠ  2.8%ï¼ŒAccuracy å‡ ä¹æ— æŸå¤±
- **StreamingLLM-1024**: è´¨é‡å‡ ä¹ä¸ Baseline ç›¸åŒï¼ŒPPL ä»…å¢åŠ  0.3%

âš ï¸ **L2 å‹ç¼©æ³¨æ„äº‹é¡¹**:
- L2 å‹ç¼©åœ¨æé«˜å‹ç¼©ç‡ä¸‹ä¼šå¯¼è‡´ä¸¥é‡çš„è´¨é‡ä¸‹é™
- é€‚åˆå¯¹è´¨é‡è¦æ±‚ä¸é«˜ä½†éœ€è¦æè‡´é€Ÿåº¦çš„åœºæ™¯

### å¯è§†åŒ–ç»“æœ

è¿è¡Œç»˜å›¾è„šæœ¬ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼š
```bash
python scripts/plot_benchmark_results.py
```

#### æ–¹æ³•æ€»è§ˆå¯¹æ¯”

![Compare All Methods](results/compare_all_methods.png)

#### StreamingLLM è¯¦ç»†æµ‹è¯•

StreamingLLM é€šè¿‡ä¿ç•™ attention sinksï¼ˆåˆå§‹ 4 tokensï¼‰+ æ»‘åŠ¨çª—å£ï¼ˆæœ€è¿‘ tokensï¼‰ï¼Œåœ¨æ˜¾è‘—å‡å°‘ cache å¤§å°çš„åŒæ—¶ä¿æŒæ¥è¿‘ baseline çš„è´¨é‡ã€‚

![StreamingLLM Benchmark](results/streaming_llm_benchmark.png)

**StreamingLLM è¯¦ç»†æ•°æ®**:

| æ–¹æ³• | TTFT(s) | TPOT(s) | ååé‡ | PPL | Accuracy | Cache |
|------|---------|---------|--------|-----|----------|-------|
| Baseline | 0.0244 | 0.0117 | 83.97 | 15.48 | 47.77% | 1999 |
| Recent-Only 256 | 0.0086 | 0.0092 | 106.82 | 48.68 | 35.49% | 256 |
| Recent-Only 512 | 0.0085 | 0.0099 | 99.28 | 32.75 | 39.27% | 512 |
| Recent-Only 1024 | 0.0085 | 0.0111 | 88.76 | 20.91 | 43.67% | 1024 |
| **Streaming 256** | 0.0085 | 0.0096 | 102.49 | 16.61 | 47.07% | 256 |
| **Streaming 512** | 0.0084 | 0.0102 | 96.06 | 15.92 | 47.57% | 512 |
| **Streaming 1024** | 0.0085 | 0.0116 | 84.69 | 15.52 | 47.72% | 1024 |

ğŸ’¡ **å…³é”®å‘ç°**: StreamingLLM ç›¸æ¯” Recent-Onlyï¼ˆçº¯æ»‘åŠ¨çª—å£ï¼‰åœ¨ç›¸åŒ cache å¤§å°ä¸‹ PPL é™ä½ 60-70%ï¼

#### Fix-Size L2 è¯¦ç»†æµ‹è¯•

Fix-Size L2 å‹ç¼©é€šè¿‡ L2 èŒƒæ•°é€‰æ‹©æ€§ä¿ç•™é‡è¦ tokenï¼Œåœ¨å›ºå®š cache å¤§å°çº¦æŸä¸‹ä¼˜äºçº¯æ»‘åŠ¨çª—å£ã€‚

![Fix-Size L2 Benchmark](results/fix_size_l2_benchmark.png)

**Fix-Size L2 è¯¦ç»†æ•°æ®**:

| æ–¹æ³• | TTFT(s) | TPOT(s) | ååé‡ | PPL | Accuracy | Cache |
|------|---------|---------|--------|-----|----------|-------|
| Baseline | 0.0165 | 0.0109 | 90.10 | 15.48 | 47.77% | 1999 |
| Recent-Only 256 | 0.0085 | 0.0091 | 107.29 | 48.68 | 35.49% | 256 |
| Recent-Only 512 | 0.0085 | 0.0098 | 99.71 | 32.75 | 39.27% | 512 |
| Fix256 kr=0.8 | 0.0086 | 0.0113 | 87.16 | 20.47 | 44.15% | 256 |
| Fix256 kr=0.5 | 0.0086 | 0.0113 | 87.32 | 19.86 | 44.82% | 256 |
| **Fix256 kr=0.3** | 0.0086 | 0.0115 | 85.27 | **19.76** | 45.05% | 256 |
| Fix512 kr=0.8 | 0.0085 | 0.0116 | 84.73 | 17.96 | 46.08% | 512 |
| **Fix512 kr=0.5** | 0.0085 | 0.0123 | 79.81 | **17.66** | 46.40% | 512 |
| Fix512 kr=0.3 | 0.0086 | 0.0124 | 79.51 | 17.83 | 46.10% | 512 |

ğŸ’¡ **å…³é”®å‘ç°**: Fix-Size L2 ç›¸æ¯” Recent-Only PPL é™ä½çº¦ 40-60%ï¼Œä½†ä¸å¦‚ StreamingLLM æ•ˆæœå¥½ã€‚

#### æ€§èƒ½æƒè¡¡åˆ†æ

![Tradeoff Analysis](results/tradeoff_analysis.png)

## å‚è€ƒæ–‡çŒ®

- **KnormPress**: [A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression](https://arxiv.org/abs/2406.11430) (EMNLP 2024)
- **StreamingLLM**: [Efficient Streaming Language Models with Attention Sinks](https://arxiv.org/abs/2309.17453) (ICLR 2024)
- **Pythia æ¨¡å‹**: [EleutherAI/pythia-70m-deduped](https://huggingface.co/EleutherAI/pythia-70m-deduped)

## æ€»ç»“

æœ¬é¡¹ç›®å®ç°äº†ç»Ÿä¸€çš„ KV Cache å‹ç¼©åº“ `kvcompress`ï¼š

âœ… **å¤šç§å‹ç¼©æ–¹æ³•**: l2_compress, fix_size_l2, streaming_llm  
âœ… **ç»Ÿä¸€æ¥å£**: æ‰€æœ‰æ–¹æ³•ä½¿ç”¨ç›¸åŒçš„å‡½æ•°ç­¾å  
âœ… **æ–¹æ³•æ³¨å†Œè¡¨**: æ–¹ä¾¿æ‰©å±•æ–°æ–¹æ³•  
âœ… **ç»Ÿä¸€è¯„ä¼°**: æ”¯æŒ PPL, Accuracy, TTFT, TPOT  
âœ… **ç»Ÿä¸€åŸºå‡†æµ‹è¯•**: å•ä¸€è„šæœ¬æµ‹è¯•æ‰€æœ‰æ–¹æ³•

### å®éªŒç»“è®º

åŸºäº Pythia-2.8B æ¨¡å‹çš„æµ‹è¯•ç»“æœï¼š

| æ¨èåœºæ™¯ | æ¨èæ–¹æ³• | æ•ˆæœ |
|---------|---------|------|
| è´¨é‡ä¼˜å…ˆ | StreamingLLM-1024 | PPL +0.3%, Acc -0.1% |
| å¹³è¡¡æ–¹æ¡ˆ | StreamingLLM-512 | ååé‡ +12%, PPL +2.8% |
| é€Ÿåº¦ä¼˜å…ˆ | L2 (kr=0.5) | ååé‡ +40%, ä½†è´¨é‡ä¸‹é™æ˜æ˜¾ |

## ä½œè€…

Jiamin Liu

## è‡´è°¢

æ„Ÿè°¢ KnormPress å’Œ StreamingLLM è®ºæ–‡ä½œè€…æä¾›çš„å¼€æºå®ç°å’Œè¯¦ç»†æ–‡æ¡£ã€‚
